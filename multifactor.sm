#! ruby
#! sidef -vWkP8
#`(exit the shell) {
  eval 'exec sidef -WkP8 $0 ${1+"$@"}'
}
##  MultiFactor, meta build system for Factor core development
##    Copyright Cat Stevens 2018
##  This program is free software: you can redistribute it and/or modify
##    it under the terms of the GNU General Public License as published by
##    the Free Software Foundation, either version 3 of the License, or
##    (at your option) any later version.
##
##    This program is distributed in the hope that it will be useful,
##    but WITHOUT ANY WARRANTY; without even the implied warranty of
##    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
##    GNU General Public License for more details.
##
##    You should have received a copy of the GNU General Public License
##    along with this program.  If not, see <https://www.gnu.org/licenses/>.

include sidefext::metatype

include lib::ABCs
include lib::msg_classes
include lib::feature
include lib::withdirectory

include providers::argparse
include providers::builtobj
include providers::cachedb
include providers::factorbash

define Hash SCRIPT = :(
  "version" => "0.3", # "
  "name" => "multifactor",
  "doc" => "a meta build system for Factor core development",
  "bug" => "github.com/catb0t/multifactor/issues",
  "license" => "GPL v3+"
)

# basic variable definitions for working with Factor from a high-level perspective
module Factor {

  define File RC_FILE = Dir.home+%f(.factor-rc)

  define Hash _config_lines_cache = []

  define Block rc_config_lines = func () -> Hash {
    Factor::_config_lines_cache[0] \\= Factor::RC_FILE.open_r.map{
      [ (.=~ /^! multifactor:(.+) ?(.*)/)[0, 1] ]
    }.grep.map{ _... }.to_h
  }

  define Block _config_cache = :()

  define Block find_config = func find_config (name, Bool must_exist = true) {
    Factor::_config_cache{name} \\= (Factor::rc_config_lines(){name} \\ do {
      must_exist && die "Required config '! multifactor:#{name}' not found in #{Factor::RC_FILE}"
      ''
    })
  }

  define Maybe::Maybe FACTOR_DIR = Maybe::maybe( Dir,  Factor::find_config('factor-dir', false) )
  define Maybe::Maybe QUIET_PIPE = Maybe::maybe( Bool, Factor::find_config('quiet-pipe', false) )
  define Maybe::Maybe DEFAULT_CHECKSUM = Maybe::maybe( String,
    Factor::find_config('default-checksum', false) || Feature::DEFAULT_CHECKSUM
  )

  # ???
  define Block say_stderr = func (String color, *args) {
    if (STDOUT.is_on_tty || (!STDOUT.is_on_tty && !Maybe::unmaybe(Factor::QUIET_PIPE, { false }) ) ) {
      STDERR.autoflush(true)

      with ( Feature::ANSIColor ) {
        STDERR.say( .color('bold', color), args..., .RESET )
      }
    }
    # else, not a TTY and quiet-pipe is true
  }
}

module MultiFactor {

  include lib::shell_words

  include Factor
  include FactorBashStateless
  include GuardIO

  include sidefext::iterable
  import sidefext::iterable::ImmutableHash

  import lib::shell_words::BuildSh

  import builtobj::DirSum
  import builtobj::SrcSums
  import builtobj::BlobSums
  import builtobj::VirtualBase64Blob
  import builtobj::TimeSpec
  import builtobj::BuiltObj

  # historical interest
  # func compare_properties (Array properties, BuiltObj b, Object o, Bool debug = false) {
  #   if (debug) {
  #     properties.map{
  #         |property|
  #       const db_property = b.method(property)()
  #       const status_property = o{property}
  #       say "Property '#{property}': #{db_property == status_property}: #{db_property.dump} == #{status_property.dump}"
  #       db_property == status_property
  #     }.all
  #   } else {
  #     properties.map{ |prop| b.method(prop)() } ~Z== o{properties...} -> all
  #   }
  # }
  struct BlobStatus {
    Bool exists = false
    Maybe::Maybe_Type checksum_match = Maybe::maybe(Bool, nil)
    Bool recompiled = false
  }

  func dump (BlobStatus b) {
    with (b) {
      "BlobStatus( exists: #{.exists}, recompiled: #{.recompiled}, checksum_match: #{Maybe::dump(.checksum_match)} )"
    }
  }

  struct AlgoBox {
    String blob
    String src
  }

  func absent_config (String rc_name, param_name = nil) {
    die "Absent config!\n\t'#{rc_name}' or '#{param_name \\ rc_name}' must be set in either the RC file ('! multifactor:#{rc_name} ...') or command line argument ('--#{param_name \\ rc_name}=...')!"
  }

  class MFRuntime (Hash options, Array factor_arguments) << lib::ABCs::SeriallyAccessible, lib::withdirectory::CapturedWriter {
    has Set known_actions = ['env-info', 'src-sums', 'run-factor', 'spoof-exists']

    has GuardIO::SLog                      log
    has providers::cachedb::CacheDB        db_man
    has GuardIO::GlobLocker                locker
    has providers::factorbash::FactorBash  fbash
    has AlgoBox                            algos

    # todo: collect generated methods that don't appear in .methods
    has Array field_groups = [
      (Bool    ¦ [:force, :debug, :info, :dry_run, :spoof_build, :clean, :basis_dev]),
      (String  ¦ [:action, :uuid, :sum_algo]),
      (Dir     ¦ [:wd]),
    ]

    has Array serial_property_generator_mfruntime = [ {
      .field_groups.map{
        const tn =
        .second.map{ |k| ((k) => .first) }.to_h
      }.reduce('merge')
    } ]

    # has Bool _force
    # has Bool _debug = false
    # has Bool _info
    # has Bool _dry_run
    # has Bool _clean
    # has Bool _sums
    # has Bool _basis_dev
    # has Str _action
    # has String _sum_blob_algo = :sha256
    # has String _sum_src_algo = :sha256
    # set in config file etc, not a cmdline option
    # has Number uuid_len
    # where the process started before any chdir
    # has Dir initial_wd
    # -> UUID ()         { self._UUID }
    # -> action          { self._action }
    # -> force           { self._force }
    # -> debug           { self._debug }
    # -> info            { self._info }
    # -> dry_run         { self._dry_run }
    # -> clean           { self._clean }
    # -> sums            { self._sums }
    # -> basis_dev       { self._basis_dev }
    # -> sum_src_algo    { self._sum_src_algo }
    # -> sum_blob_algo   { self._sum_blob_algo }
    # -> wd { self.initial_wd }
    # -> UUID (Str u)             { self._UUID = u; self }
    # -> action (Str a)           { self._action = a; self }
    # -> force (Bool b)           { self._force = b; self }
    # -> debug (Bool b)           { self._debug = b; self }
    # -> info (Bool b)            { self._info = b; self }
    # -> dry_run (Bool b)         { self._dry_run = b; self }
    # -> clean (Bool b)           { self._clean = b; self }
    # -> sums (Bool b)            { self._sums = b; self }
    # -> basis_dev (Bool b)       { self._basis_dev = b; self }
    # -> sum_src_algo (Str a)     { self._sum_src_algo = a; self }
    # -> sum_blob_algo (Str a)    { self._sum_blob_algo = a; self }

    has Array init_steps_10_mfruntime = [ {
        |self|
      self.uuid( GuardIO::make_uuid(words: true) )
      # say "MFRuntime: #{self.uuid}"
      self.wd( Dir.cwd )
      # need to use field_groups here
      Hash(
        :action => Block.identity,
        :sum_algo => String
      ).merge(
        [:force, :dry_run, :info, :clean, :basis_dev, :spoof_build] \
          .map{ ( (_) => Bool ) }.to_h # all these parentheses are important
      ).each_kv{
          |name, convert|
        self.method( name )( convert( self.options(){ name.replace_all("_", "-") } ) )
      }

      with (self.sum_algo || Maybe::unmaybe(Factor::DEFAULT_CHECKSUM, { absent_config('default-checksum', :sum_algo) }) ) {
        self.algos = AlgoBox( [ _ ]*2 ... )
      }

      const Dir factor_dir = Dir( with ( 'factor-dir' ) {
          self.options(){_} || Maybe::unmaybe(Factor::FACTOR_DIR, { absent_config(_) } )
      } )

      const Bool is_trace = ( [:trace, :verbose, 'dry-run'].any{ self.options(){_} } )
      const Bool is_verbose = ( [:verbose, 'dry-run'].any{ self.options(){_} } )
      const Bool subcommand_output = Bool( with ( self.options ) {
        .{'no-quiet-subcom'} || ( .{'quiet-subcom'} \\ Maybe::unmaybe(
          Factor::QUIET_PIPE,
          { absent_config('quiet-pipe', '[no-]quiet-subcom') }
        ) )
      } )

      # need a way for the consumer ofthe ArgParse API to know the exact syntax of the command line
      self.known_actions.contains(self.action) \
        || die "[FATAL] #{__FILE__, __LINE__}: init_steps_mfruntime: don\'t know action '#{self.action}' [--action | -a]"

      # initialise helper objects
      self.log = GuardIO::SLog( is_trace: is_trace, is_verbose: is_verbose, logger: Factor::say_stderr )

      self.fbash = providers::factorbash::FactorBash(
        factor_dir,
        self.algos.src,
        self.basis_dev,
        subcommand_output: subcommand_output,
        spoof_build: self.spoof_build
      )

      self.db_man = providers::cachedb::CacheDB().setup( :(
          :dir =>              self.options(){'db-dir'},
          :filename_base =>    self.options(){'db-name'},
          :dry_run =>          self.dry_run,
          :verbose =>          is_verbose,
          :trace =>            is_trace,
          :replace_existing => self.options(){'from-scratch'},
          :element_type =>     BuiltObj,
          # :logger => self.log # separate or same loggers?
      ) )
      # assert_eq( self.db_man.element_type, BuiltObj )
      # say self.options
      self.locker = GuardIO::GlobLocker().setup( :(
        :uuid => self.uuid,
        :remove_old_lock => self.options(){'remove-old-lock'},
        :lock_ext => '.multifactor_lock',
        :locked_fods => [ self.db_man.db_name, self.fbash.wd ],
        :verbose => is_verbose,
        :trace => is_trace
      ) )

      self.log.trc(__FILE__, __LINE__, :init_steps_10_mfruntime, "finished configuration") #, wd now: '#{self.db_dir}'")
    } ]

    method destroy (Bool is_exc, Hash exc_info, *rest) {
      const type = (is_exc && Combi::rescope( lib::msg_classes::classify( exc_info{:msg} ) )({
          |type, fields|
        self.log.wrn(__FILE__, __LINE__, __METHOD_NAME__, "#{__CLASS_NAME__}: destructor called!\n\t#{type} :: #{fields.grep_kv{ .!= :block_tried_invoke }}\n")
        type
      }))
      # say "IS_EXC: #{is_exc}"
      [self.db_man, self.locker].map{ .destroy(is_exc, exc_info) }
      type
    }

     method show_info { ... }
     #  say "MultiFactor #{self.UUID} options"
     #  say "\tverbose: #{self.verbose}\tinfo: #{self.info}\ttrace: #{self.trace}\tdry_run: #{self.dry_run}"
     #  say "\tclean: #{self.clean}\tsums: #{self.sums}\tdb_name: #{self.db_name}\tdb_path: #{self.db_path}"
     #  say "\tfactor_path: #{self.factor_path}\tdb: #{self.db}\tremove_old_lock: #{self.remove_old_lock}"
     #  say "\tFactor arguments: #{self.factor_arguments}"
     #}

    -> _blob_file_contents_sum (File f, Str algo) -> String {
      # self.log.vbs(__FILE__, __LINE__, __METHOD_NAME__, "checksumming #{f} with algorithm '#{algo}'")
      # give checksum of empty file, or die?
      self.spoof_build ? '' : self.fbash.with_directory{
        (f.exists && BuildSh.blob_file_contents_sum(f, algo || self.algos.blob)) \
          || die "[FATAL] #{__METHOD_NAME__}: empty algo: file: #{f}"
      }
    }

    # -> current_status_to_builtobj (Hash status) -> BuiltObj {
    #   self.log.vbs(__FILE__, __LINE__, __METHOD_NAME__, 'creating BuiltObj from scratch')
    #   var bo = BuiltObj().id(self.uuid)
    #   status.each_kv{
    #       |prop, val|
    #     # self.vbs(__FILE__, __LINE__, __METHOD_NAME__, "invoke method / property '#{prop}'")
    #     say "got here: #{prop} '#{status{prop}}'"
    #     bo.method(prop)( val )
    #   }
    #   self.log.vbs(__FILE__, __LINE__, __METHOD_NAME__, 'setting creation time')
    #   bo.time_created(Time.now)
    # }

    -> _compile_vm_lib (BuiltObj bo) {
      if ( ! self.fbash.build_factor(bo) ) {
        # self.locker.cleanup
        die "vm compilation failed!"
      }
      self.log.vbs(__FILE__, __LINE__, __METHOD_NAME__, "vm/lib compiled")
      true
    }

    -> compile_vm_lib (BuiltObj bo, String caller_name = "") -> Bool {
      # no double jeopardy; technically redundant but that's okay
      if (caller_name == :maybe_recompile_target) {
        static var have_compiled = false
        if (! have_compiled) {
          self.log.vbs(__FILE__, __LINE__, __METHOD_NAME__, "vm/lib compiling for 1st time")
          self._compile_vm_lib(bo)
          have_compiled = true
        } else {
          self.log.vbs(__FILE__, __LINE__, __METHOD_NAME__, "vm/lib not recompiled: #{caller_name}: no double jeopardy")
        }
        true
      } else { self._compile_vm_lib(bo) }
    }
    -> compile_vm (o, c)  { self.compile_vm_lib(o, caller_name: c) }
    -> compile_lib (o, c) { self.compile_vm_lib(o, caller_name: c) }

    -> compile_image (BuiltObj bo) -> Bool {
      if (! self.fbash.build_image(bo) ) {
        # self.locker.cleanup
        die "image compilation failed!"
      }
      self.log.vbs(__FILE__, __LINE__, __METHOD_NAME__, "image compiled")
      true
    }

    # NOTE: modifies obj
    -> sum_save_boot_image (BuiltObj bo) {
      self.log.trc(__FILE__, __LINE__, __METHOD_NAME__, "saving boot image sums for #{bo.boot_fullname}")
      const disk_sum_toplevel = self._blob_file_contents_sum(bo.boot_fullname, bo.blob_algorithm)

      if ( disk_sum_toplevel != bo.blob_sums.boot ) {
        bo.blob_sums( BlobSums(
          algo: bo.blob_algorithm || self.algos.blob,
          boot: disk_sum_toplevel,
          # set the rest of the properties to their old values
          [:vm, :lib].map{
              |n|
            n ¦ bo.blob_sums.method(n)
          }...
        ))
      }

      const disk_sum_stored = self._blob_file_contents_sum(bo.boot_fullname, bo.stored_boot_image.algo)

      if ( disk_sum_stored != bo.stored_boot_image.sum ) {
        bo.stored_boot_image( VirtualBase64Blob(
          sum: disk_sum_stored,
          data: self.fbash.with_directory{ GuardIO::read_binary_b64(bo.boot_fullname) },
          algo: (bo.stored_boot_image.algo || bo.blob_algorithm || self.algos.blob)
        ) )
      }
    }

    # complex check for vm and lib
    -> maybe_recompile_target (BuiltObj match_bo, BlobSums cur_blob_sums, String target, Hash previous_recompiled) {
      const MN = __METHOD_NAME__
      ((target) => match_bo.method(target + :_fullname)().rescope{
          |target_fullname|
        (! previous_recompiled{target} ) || if (
          match_bo.rescope{
              # |b|
            self.fbash.with_directory{
              const exists = target_fullname.exists
              const disk_sum = self._blob_file_contents_sum( target_fullname, .blob_algorithm )
              const matched_sum = .blob_sums.method(target)()
              const sum_indirect = (defined(cur_blob_sums)
                ? ( .blob_sums.method(target)() =~ cur_blob_sums.method(target)() )
                : nil)
              (! exists) || ((disk_sum != matched_sum) && (sum_indirect == false))
            }
          }
        ) {
          self.log.trc(__FILE__, __LINE__, MN, "NOT EXIST/MATCH #{target} named '#{target_fullname}' rebuilding")
          self.method(:compile_ + target)(match_bo, __METHOD_NAME__)
          # true
        } else {
          self.log.vbs(__FILE__, __LINE__, MN, "EXIST+MATCH #{target} named '#{target_fullname}' not rebuilding")
          false
        }
      })
    }

    -> _algo (BuiltObj prefer) is cached -> String { prefer.blob_algorithm || self.algos.blob }

    -> _make_disk_blob_sums (BuiltObj bo, Hash targets) -> BlobSums {
      self.fbash.with_directory{
        BlobSums(
          # TODO: algo
          algo: self._algo(bo),
          targets.map_kv{
              |name, test|
            ( name ⫶ test || self._blob_file_contents_sum( bo.method(name + :_fullname)(), self._algo(bo) ) )
          }...
        )
      }
    }

    -> build_new_factor (BuiltObj current_status) {
      const MN = __METHOD_NAME__

      self.log.trc(__FILE__, __LINE__, MN, 'no match in db!')
      # interpret the current_status keys as property (setter) names in BuiltObj
      # this call does not set all properties, only those listed in status_properties
      current_status.dclone.unlock.id(self.uuid).timespec( TimeSpec().created(Time.now) ).cleave(
        { |n| self.compile_vm_lib(n) },
        { |n| self.compile_image(n)  },
        { |n| n.blob_sums( self._make_disk_blob_sums(n, [:vm, :lib, :boot]) ) },
        { |n| self.sum_save_boot_image(n) }, # modifies n
        { .lock },
        { self.log.trc(__FILE__, __LINE__, MN, 'writing the new BuiltObj to disk db because it changed') },
        { self.db_man.insert(_) },
        { self.log.trc(__FILE__, __LINE__, MN, "ok, running factor!") },
        # { self.destroy( false, :() ) },
        { self._detach_factor_thread(_.vm_fullname) }
      )
    }

    -> _tombstone_entry (BuiltObj bo, Array TARGETS) {
      const tombstoning = (bo |> :dclone |> :unlock)
      del bo
      tombstoning.timespec.tombstoned(Time.now)

      self.db_man.insert(tombstoning)
      self.capture_write_disk(__METHOD_NAME__, { TARGETS.each{ tombstoning.method(_ + :_fullname)().remove } } )
    }

    # multifactor's actual entry point
    # TODO: make this asynchronous, so that with_directory stuff is
    # done in a separate actor and awaited

    # DONE: dynamic hash algo selection
    # TODO: read mtimes
    # TODO: test whether the images are older than the file mtimes?!
    # TODO: write mtime/atimes
    # TODO: testability
    # DONE: if branches
    # DONE: make use of git information
    # DONE: compare OS, ARCH, WORD SIZE information
    # TODO: image compression?

    #TDOO: DON"T HASH FACTOR IMAGE
    method go (Bool is_restart = false) {
      const MN = __METHOD_NAME__
      if (self.info) { self.show_info; return nil }

      self.locker.do_lock_files
      given (self.action) {
        when ('src-sums') {
          self.fbash.say_src_sums
          return self.destroy
        }
        when ('env-info') {
          self.fbash.say_env_info
          return self.destroy
        }
      }

      # property names in BuiltObj, used to create current_status
      # BuildSh and FactorBash implement these through FactorBash.delegate
      define Set status_properties = Set(
        :factor_version, :is_git, :git_branch, :git_hash,
        :os_type, :os_name, :arch_name, :word_size,
        :vm_format, :image_format, :lib_format, :boot_format,
        :blob_algorithm, :src_sums
      )
      var BuiltObj current_status = BuiltObj().blob_algorithm( self.algos.blob )
      status_properties.each{
        with ( self.fbash.delegate( _ ) ) { |v| current_status.method( _ )( v ) }
      }
      const ImmutableHash db_data = self.db_man.data
      if (self.debug) {
        #say current_status.dump
        #say db_data.dump
      }

      self.log.wrn(__FILE__, __LINE__, MN, 'make this const again')
      var match_bo = db_data.values.find{
          |b|
        # remember, we're not testing *all* properties like .lock or tombstoned
        current_status._serial_eq(b, incl: status_properties)
      }
      # need to generate new ID and compile
      if (!match_bo && (self.action != 'spoof-exists')) { return self.build_new_factor(current_status) }
      match_bo = current_status.dclone
      # ...
      # now this is definitely defined
      match_bo.lock
      define TARGETS = :( :vm => true, :lib => true, :image => false )

      if ( ! Set(:never, 0, nil).has(match_bo.timespec.tombstoned) ) {
        say '!!! matching entry is tombstoned!'
        # need to trash the old entry
        self._tombstone_entry(match_bo, TARGETS.grep{ .[1] }.keys)
        return self.build_new_factor(current_status)
      }

      self.log.vbs(__FILE__, __LINE__, MN, 'matching object in db')

      # if either the vm or lib are missing or out of date, recompile them
      #   if the checksums don't match after both have been recompiled, stop
      const Hash blob_stats = TARGETS.map_kv{
          |k, v|
        # say "blob_stats 1" say "blob stats 2" &&
        const target_fullname = match_bo.method( k + :_fullname )
        const e = target_fullname.exists
        # const new_v =
        # say new_v
        ( (k) => BlobStatus(
          exists: e,
          recompiled: false,
          checksum_match: Maybe::maybe(Bool, !e ? nil : (current_status.blob_algorithm==self._algo(match_bo) \
            && current_status.blob_sums.method(k)==self._blob_file_contents_sum( target_fullname(), self._algo(match_bo) ) ) )
        ) )
      }

      blob_stats.each_kv{
          |k, v|
        say "t: #{k} : #{dump(v)}"
      }
      ...

      # NOTE: compiling only the lib can be done in parallel with the next step
      # next, if the image is missing, rebuild it
      # don't update the database's blob sums if the blob wasn't recompiled

      -> do_recompile_needed (BlobSums cur_blob_sums = nil, Hash previous_recompiled = nil) -> Hash {
        [
          TARGETS.map{ self.maybe_recompile_target(match_bo, cur_blob_sums, _, previous_recompiled) }...,
          :image => (
            (false == previous_recompiled{:image} )
              ? false
              : self.fbash.with_directory{ match_bo.image_fullname.exists ? false : self.compile_image(match_bo) }
            )
        ].to_h
      }

      self.log.vbs(__FILE__, __LINE__, MN, "NOTE: no checksums in main path yet")
      # ...
      var (
        new_recompiled = do_recompile_needed(),
        current_blob_sums = self._make_disk_blob_sums(match_bo, TARGETS)
      )
      # self.log.vbs(__FILE__, __LINE__, MN, "NOTE: ONCE: #{new_recompiled}")

      new_recompiled = do_recompile_needed(cur_blob_sums: current_blob_sums, previous_recompiled: new_recompiled)
      current_blob_sums = (new_recompiled.values.all{ !_ }
        ? current_blob_sums
        : self._make_disk_blob_sums(match_bo, TARGETS))

      # self.log.vbs(__FILE__, __LINE__, MN, "NOTE: TWICE: #{new_recompiled}")
      self.log.trc(__FILE__, __LINE__, MN, "done calculating checksums / rebuilding")

      # if they STILL don't match, delete the files + tombstone the entry and quit
      if ( ! (current_blob_sums =~ match_bo.blob_sums) ) {
        self.log.trc(__FILE__, __LINE__, MN, 'blob sums still mismatched!')
        if (is_restart) {
          self.log.trc(__FILE__, __LINE__, MN, "i give up (already in a restart)")
          return self.destroy
        }
        self.log.trc(__FILE__, __LINE__, MN, "starting over...")
        self._tombstone_entry(match_bo, TARGETS)
        return self.go(is_restart: true)
      }

      # OK, going to update the DB and run Factor

      # only updating the blob sums IFF the blob was newly compiled
      # otherwise, just update the mod/access times and run count
      const new_match_bo = match_bo.cleave( { .lock }, { .dclone } ).last
      if ( [ new_recompiled{ TARGETS... } ].any{ _ == true } ) {
        self.log.vbs(__FILE__, __LINE__, MN, 'writing memory BuiltObj because of the newly compiled VM')
        new_match_bo.blob_sums(current_blob_sums)
        new_match_bo.time_modified(Time.now)
      }

      new_match_bo.lock

      # ?????
      const changed_db = if (match_bo != new_match_bo) {
        self.log.trc(__FILE__, __LINE__, MN, 'writing the new BuiltObj to disk db because it changed')
        self.db_insert(new_match_bo)
        true
      }

      # say "Eventual successful configuration!"
      # say "\tmatching_vm_name:\t'#{matching_vm_name}' # #{disk_vm_sum[0..10]}...\tmatching_image_name:\t'#{matching_image_name}' #{disk_image_sum[0..10]}..."
      # say "\tvm_sums_match:\t\t#{vm_blob_sums_match}/#{new_vm_blob_sums_match}"
      # say "\timage_sums_match:\t#{image_blob_sums_match}/#{new_image_blob_sums_match}"
      # say "\tchanged_db:\t\t#{changed_db}\t\t\tnewly_compiled: #{newly_compiled.to_s.chars.grep{|p|![\"\n\",' '].any{p==_} }.join}"
      self.log.trc(__FILE__, __LINE__, MN, "ok, running factor!")
      self.destroy
      self._detach_factor_thread(match_bo.vm_fullname)
    }

    -> _detach_factor_thread (String vm_name) {
      const MN = __METHOD_NAME__
      {
        self.log.inf(__FILE__, __LINE__, MN, 'Launching Factor: ', "'", vm_name, self.factor_arguments..., "'")
        if ( self.fbash.with_directory{
            [Command::spawn_se('./' + vm_name, self.factor_arguments..., output: false)]
        } ) {
          self.log.wrn(__FILE__, __LINE__, MN, "Failed!")
        }
      }.thr.detach
      # don't segfault
    }
  }
}

define MICRO_MAGNITUDE = 1_000
func μsec { Time.micro*MICRO_MAGNITUDE }
func μsec (Number n) { Time.micro*MICRO_MAGNITUDE - n }

func main {
  const μs = μsec()
  μs
  # say Factor::RC_FILE
  # say Factor::REPO
  # say Factor::VERSION
  # say Dir.cwd
  # say Dir.cwd
  # Dir.chdir(Factor::REPO)
  # say BuildSh::generate_make_targets()
  # say FactorBash::sum_git_names_matching(/\.s(?:m|f)/)
  # say FactorBash::sum_git_contents_matching(/\.s(?:m|f)/)
  # say MultiFactor::BuiltObj(([""] * 15)..., false ).dump.len

  const parser = providers::argparse::ArgParse(ARGV) \
    .info(SCRIPT) \
    .option(:force, :f, doc: 'Force a rebuild in any case') \
    .option(:trace, :t, doc: 'Some debug tracing') \
    .option(:verbose, :V, doc: 'Verbose debug tracing') \
    .option(:info, :i, doc: 'Just show configuration information') \
    .option('dry-run', :n, doc: 'Change no disk files') \
    .option('from-scratch', :g, doc: 'ignore existing DB (debug)') \
    # .option('sums', :c,  negate: (:Always ¦ :Never), doc: 'use checksums') \
    # TODO
    .option('sum-algo', :k,  param: (:algo ¦ :sha256), doc: 'Checksum algorithm to use') \

    .option('db-name', :D, param: (:name ¦ '.multifactor.db'), doc: 'Custom database filename') \
    .option('db-dir', :d, param: (:dir ¦ '.'), doc: 'Directory containing database') \
    .option('factor-dir', :w, param: (:dir ¦ "."), doc: 'Path to Factor working directory') \
    .option('remove-old-lock', :R, doc: 'Blindly remove any lock files (unsafe!)') \
    .option('quiet-subcom', :q, negate: (:Never ¦ :Always), doc: 'show subcommand outputs') \
    # TODO: argparse can accept a list of allowed values
    .option(
      :action, :a, param: (:name ¦ 'run-factor'),
      doc: "Perform this action\nactions: run-factor, src-sums, env-info"
    ) \
    .option('basis-dev', :b, doc: "Ignore changes in basis/\n(basis development mode)") \
    .option('spoof-build', :s, doc: "Don't actually compile or build anything") \
    .use_option_terminator('Further arguments are given to Factor') \
    # .use_stdin_file_arg \
    # .use_arg_list_terminator \
    # .ignore_unknowns \
    # .help_on_stderr \
    .arg("arg...", doc: "Arguments to the final Factor VM")

  var (opts, args, *_) = parser.go...
  # say "#{opts} #{args} #{_}"

  const destroy_mf = Combi::FinalizerSpec(
    obj: MultiFactor::MFRuntime(opts, args.keys).debug(true),
    shared_f7rs: [[:destroy]],
    exc_only: false
  )

  const done = Combi::with_destructors( destroy_mf )({
    .go
  })
  # say Combi::dump(done)
  with (done) {
   if (!.success) {
     Combi::rescope( lib::msg_classes::classify( .{:exc_info}{:msg} ) )({
         |type, fields|
       Factor::say_stderr('red', "~MFRuntime called due to runtime error: #{type} :: #{fields.grep_kv{ .!= :block_tried_invoke }}\n")
     })
     # #{Combi::dump(_)}
   }
  }

  Factor::say_stderr('bold bright_white', "\n\tΔ#{μsec(μs)} ×1,000μ")
}

if (__FILE__ == __MAIN__) {
  with ( Feature::ANSIColor ) {
    say ( .color('bright_green'), SCRIPT{:name}, ' entrypoint main()', .RESET)
  }
  main()
}
